import sys
import argparse
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import norm, pearsonr, zscore
from scipy.spatial.distance import squareform
from statsmodels.stats.multitest import multipletests
from sklearn import datasets, linear_model
import nibabel as nib
import scipy.io
import os
from scipy.interpolate import interp1d
from scipy import stats
from sklearn.metrics import mean_squared_error


file_path = os.path.dirname(os.path.realpath(__file__))
file_path_try = file_path.split('\\')
if len(file_path_try) == 1:
    file_path_try = file_path.split('/')
    root_path = '/'.join(file_path_try[:-2]) + '/'
else:
    root_path = '\\'.join(file_path_try[:-2]) + '\\'

sys.path.append(os.path.join(root_path, 'tools'))
from isc_standalone import isc, isfc, phase_randomize

parser = argparse.ArgumentParser(
    description="Calculate Pearson Correlation between original time series and behavioral signal")
parser.add_argument("-i", "--input", type=int, nargs=1, help="regional level: 0=node, 1=edge, 2=state", default=0)
parser.add_argument("-s", "--state",  nargs=3, help="state hyperparameters, need when regional level is state; [K, delta, iter_tmp]", default=[4, 0.3, 5])
parser.add_argument("-p", "--iter", type=int, nargs=1, help="iteration to generate null distribution", default=500)
args = parser.parse_args()

def get_statistics(model, train_df=None, target_df=None):
    params = np.append(model.intercept_, model.coef_)
    prediction = model.predict(train_df)
    if len(prediction.shape) == 1:
        prediction = np.expand_dims(prediction, axis=1)
    ones_m=np.ones((train_df.shape[0],1)) #add ones column
    new_trainset=np.hstack([ones_m,train_df]) 
    MSE = mean_squared_error(prediction, target_df)
    variance = MSE * (np.linalg.inv(np.dot(np.transpose(new_trainset), new_trainset)).diagonal())       # MSE = (1, ) & else = (n, ) 가 나와야 함.
    std_error = np.sqrt(variance)
    t_values = params / std_error
    p_values = [2 * (1 - stats.t.cdf(np.abs(i), (new_trainset.shape[0] - new_trainset.shape[1] - 1))) for i in t_values]
    std_error = np.round(std_error, 6)
    t_values = np.round(t_values, 3)
    p_values = np.round(p_values, 4)
    params = np.round(params, 4)
    return params[:], std_error[:], t_values[:], p_values[:]

# load data(X : behavioral data, Y : neural activation or edge connetivity)
neuro_data_whole = scipy.io.loadmat(os.path.join(root_path, "data", "ts_all.mat"))
beh_data_whole = np.load(os.path.join(root_path, "data", "behav","dISC_signal_data.npz"))
signal_hrf_labels = beh_data_whole['signal_hrf_labels']
beh_data_whole = beh_data_whole['dISC_signal']
print(beh_data_whole.shape)  # (54, 10, 3150)
print(signal_hrf_labels) 
for bi in range(len(signal_hrf_labels)):
    globals()[signal_hrf_labels[bi]] = np.squeeze(beh_data_whole[:,bi,:])

Nsubj = beh_data_whole.shape[0]
ts_all = neuro_data_whole['ts_all_'+str(Nsubj)+'sub']
tp = int(np.shape(ts_all)[0]/Nsubj)
Nnodes = np.shape(ts_all)[1]
Nedges = int(Nnodes*(Nnodes-1)/2)
TR = 1.5
window_len = 21

x = np.linspace(0, int(tp-window_len-1), int(tp-window_len))
xq = np.linspace(x.min(), x.max(), int((tp-window_len) * TR * 10))
region_level = args.input[0]
region_level_label = dict({0 : 'node', 1: 'edge', 2: 'state', 3: 'system'})
print("GLM between dISC time series of each " + region_level_label[region_level] +  
      " and behavioral signal")
if region_level == 2:
    K = args.state[0]
    delta = args.state[1]
    iter_tmp = args.state[2]
    print('GLMM hyperparamters for states: ', K, delta, iter_tmp)

## neuro data
neuro_data = np.zeros([Nsubj, tp, Nnodes])
for si in range(Nsubj):
    tmp_ts = ts_all[0 + si*tp : tp + si*tp]
    neuro_data[si] = tmp_ts

neuro_data = np.moveaxis(neuro_data, 0, 2)  # [tp x Nnode x Nsubj]
if region_level == 0:
    window_iscs_loo = np.empty([Nsubj, Nnodes, 1])
    for ti in range(tp - window_len):
        window_data = neuro_data[ti:(ti + window_len),...]
        tmp_window_iscs_loo = isc(window_data, pairwise=False)  # [54(Nsubj) x 147(Nnodes)]
        tmp_window_iscs_loo = np.expand_dims(tmp_window_iscs_loo, axis = 2)  # [54(Nsubj) x 147(Nnodes) x 1]
        window_iscs_loo = np.concatenate([window_iscs_loo, tmp_window_iscs_loo], axis = 2)
    window_iscs_loo = window_iscs_loo[:,:,1:]
    print(np.shape(window_iscs_loo))  # [54(Nsubj) x 147(Nnodes) x 210(tp-window_len)]
    window_iscs_loo = np.swapaxes(window_iscs_loo, 0, 2)  
    print(np.shape(window_iscs_loo)) # [210(tp-window_len) x 147(Nnodes) x 54(Nsubj) ]
    tmp = interp1d(x, window_iscs_loo, kind = 'quadratic', axis = 0)
    Y_values = tmp(xq)    
    Nregions = Nnodes
elif region_level == 1:
    tmp_data = np.load(os.path.join(root_path, 'results', 'isc', 'dISFC.npz')) # <- generated by isc_analysis.ipynb
    con_window_isfcs_loo = tmp_data['con_window_isfcs_loo']  #(3150, 10731, 54)
    tmp = interp1d(x, con_window_isfcs_loo, kind = 'quadratic', axis = 0)
    con_window_isfcs_loo_interpd = tmp(xq)
    
    v = squareform(np.linspace(0,Nedges-1,Nedges))
    tmp = scipy.io.loadmat(os.path.join(root_path, 'data', 'ROE_dopa.mat'))
    ROE_idx = tmp['mat']
    tmp = np.where(ROE_idx)
    ROE_ir = tmp[0]
    ROE_ic = tmp[1]
    ROE_IDX_dopa = list()
    for ii in range(len(ROE_ir)):
        ROE_IDX_dopa.append(int(v[ROE_ir[ii], ROE_ic[ii]]))
    neuro_con_data_interp_ROE_dopa = con_window_isfcs_loo_interpd[:,ROE_IDX_dopa,:]

    tmp = scipy.io.loadmat(os.path.join(root_path, 'data', 'ROE_3system.mat'))
    ROE_idx = tmp['mat']
    tmp = np.where(ROE_idx)
    ROE_ir = tmp[0]
    ROE_ic = tmp[1]
    ROE_IDX_3system = list()
    for ii in range(len(ROE_ir)):
        ROE_IDX_3system.append(int(v[ROE_ir[ii], ROE_ic[ii]]))
    neuro_con_data_interp_ROE_3system = con_window_isfcs_loo_interpd[:,ROE_IDX_3system,:]
elif region_level == 2:
    glmm_data = scipy.io.loadmat(os.path.join(root_path, 'results','glmm','glmm_k'+str(K)+'_'+str(delta)+'.mat'))
    gamma_hats_iter = glmm_data['gamma_hats_iter']
    gamma_hats = np.squeeze(gamma_hats_iter[:,:,iter_tmp-1])
    gamma_hats_tmp = np.reshape(gamma_hats, [Nsubj, tp, K])
    gamma_hats_tmp = np.moveaxis(gamma_hats_tmp, 0, 2)  # [tp, K, Nsubj]
    window_iscs_state_loo = np.empty([Nsubj,K])
    for ti in range(tp - window_len):
        window_data = gamma_hats_tmp[ti:(ti + window_len),...]
        tmp_window_iscs_state_loo = isc(window_data, pairwise=False)  # [54(Nsubj) x 4(states)]
        window_iscs_state_loo = np.dstack([window_iscs_state_loo, tmp_window_iscs_state_loo])
    window_iscs_state_loo = window_iscs_state_loo[:,:,1:]
    print(np.shape(window_iscs_state_loo))  # [54(Nsubj) x 4(states) x 210(tp-window_len)]
    window_iscs_state_loo = np.swapaxes(window_iscs_state_loo, 0, 2)  
    print(np.shape(window_iscs_state_loo)) # [210(tp-window_len) x 4(states) x 54(Nsubj) ]
    tmp = interp1d(x, window_iscs_state_loo, kind = 'quadratic', axis = 0)
    Y_values = tmp(xq)
    Nregions = K
elif region_level == 3:
    system_con_data = scipy.io.loadmat(os.path.join(root_path, 'results', 'leida', 'Leida_eig.mat'))['inter_vec']
    Nregions = system_con_data.shape[1]  # 28
    system_con_data = np.reshape(system_con_data, [Nsubj, tp, Nregions])
    system_con_data = np.moveaxis(system_con_data, 0, 2)  # [tp x 28 x Nsubj]
    window_iscs_systemcon_loo = np.empty([Nsubj, Nregions])
    for ti in range(tp - window_len):
        window_data = system_con_data[ti:(ti + window_len),...]
        tmp_window_iscs_systemcon_loo = isc(window_data, pairwise=False)  # [54(Nsubj) x 4(states)]
        window_iscs_systemcon_loo = np.dstack([window_iscs_systemcon_loo, tmp_window_iscs_systemcon_loo])
    window_iscs_systemcon_loo = window_iscs_systemcon_loo[:,:,1:]
    print(np.shape(window_iscs_systemcon_loo))  # [54(Nsubj) x 28 x 210(tp-window_len)]
    window_iscs_systemcon_loo = np.swapaxes(window_iscs_systemcon_loo, 0, 2)  
    print(np.shape(window_iscs_systemcon_loo)) # [210(tp-window_len) x 28 x 54(Nsubj) ]
    tmp = interp1d(x, window_iscs_systemcon_loo, kind = 'quadratic', axis = 0)
    Y_values = tmp(xq)  

DS1 = np.expand_dims(Precision_hrf, axis = 2)
DS2 = np.expand_dims(Pos_prediction_error_hrf, axis = 2)
DS3 = np.expand_dims(Neg_prediction_error_hrf, axis = 2)
DS4 = np.expand_dims(AS_hrf, axis = 2)
DS5 = np.stack([AS_hrf, Precision_hrf], axis = 2)
DS6 = np.stack([Pos_prediction_error_hrf, Precision_hrf], axis = 2)
DS7 = np.stack([Neg_prediction_error_hrf, Precision_hrf], axis = 2)
DS8 = np.expand_dims(FVS_w_hrf, axis = 2)
DS9 = np.expand_dims(FVS_l_hrf, axis = 2)
DS10 = np.stack([FVS_w_hrf, Precision_hrf], axis = 2)
DS11 = np.stack([FVS_l_hrf, Precision_hrf], axis = 2)
DS12 = np.stack([AS_hrf, FVS_l_hrf, Precision_hrf], axis = 2)
DS13 = np.stack([AS_hrf, FVS_w_hrf, Precision_hrf], axis = 2)
DS14 = np.stack([AS_hrf, FVS_w_hrf], axis = 2)

num_m = int(list(globals().keys())[-1][2:])
MAX_RANDOM_SEED = 2**32 - 1

num_iter = args.iter[0]
print(num_iter, 'iteration will be started')

result_path = os.path.join(root_path,'results','GLM')
if not os.path.exists(result_path):
    os.makedirs(result_path)

# mass GLM
for di in range(1, num_m+1):
    EV_name = 'DS'+str(di)
    if EV_name in locals():
        print('DS:', di)
        X = globals()['DS{}'.format(di)]
        params_mass = np.zeros([Nregions, Nsubj, X.shape[2]+1, num_iter])
        std_error_mass = np.zeros([Nregions, Nsubj, X.shape[2]+1, num_iter])
        t_values_mass = np.zeros([Nregions, Nsubj, X.shape[2]+1, num_iter])
        p_values_mass = np.zeros([Nregions, Nsubj, X.shape[2]+1, num_iter])
        random_state=None
        for iter in range(num_iter):
            print('iter : ', iter)
            if isinstance(random_state, np.random.RandomState):
                prng=random_state
            else:
                prng = np.random.RandomState(random_state) 
            shifted_Y = phase_randomize(Y_values, voxelwise=True, random_state=prng)
            for roi in range(Nregions):
                for si in range(Nsubj):
                    regr = linear_model.LinearRegression() # set up model
                    Xx = X[si,:,:]  # [3150, 6]
                    Y = shifted_Y[:,roi,si]  # [3150 x 1]
                    regr.fit(Xx, Y) # fit model
                    params_tmp, std_error_tmp, t_values_tmp, p_values_tmp = get_statistics(regr,Xx,Y)
                    params_mass[roi, si, :, iter] = params_tmp
                    std_error_mass[roi, si, :, iter] = std_error_tmp
                    t_values_mass[roi, si, :, iter] = t_values_tmp
                    p_values_mass[roi, si, :, iter] = p_values_tmp
            random_state = np.random.RandomState(prng.randint(0, MAX_RANDOM_SEED))
        scipy.io.savemat(os.path.join(result_path,'null_dISC_'+region_level_label[region_level]+'_DS'+str(format(di, '02'))+'.mat'), 
                         {'params_mass':params_mass, 'std_error_mass':std_error_mass, 't_values_mass':t_values_mass, 'p_values_mass':p_values_mass})
        del X
        del globals()['DS{}'.format(di)]
